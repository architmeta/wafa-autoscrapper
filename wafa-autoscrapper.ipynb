{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a05786-be9a-4215-b3cd-ea04f88a6ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 04:16:57,765 - INFO - Scraping page 1: https://english.wafa.ps/Pages/LastNews?pageNumber=1\n",
      "2025-04-17 04:16:58,947 - INFO - Found 50 articles with selector div.post-wrap\n",
      "2025-04-17 04:16:58,994 - INFO - Page 1: Extracted 50 articles\n",
      "2025-04-17 04:16:58,994 - INFO - Scraping page 2: https://english.wafa.ps/Pages/LastNews?pageNumber=2\n",
      "2025-04-17 04:17:00,109 - INFO - Found 50 articles with selector div.post-wrap\n",
      "2025-04-17 04:17:00,148 - INFO - Page 2: Extracted 50 articles\n",
      "2025-04-17 04:17:00,148 - INFO - Scraping page 3: https://english.wafa.ps/Pages/LastNews?pageNumber=3\n",
      "2025-04-17 04:17:01,262 - INFO - Found 50 articles with selector div.post-wrap\n",
      "2025-04-17 04:17:01,293 - INFO - Page 3: Extracted 50 articles\n",
      "2025-04-17 04:17:01,293 - INFO - Scraping page 4: https://english.wafa.ps/Pages/LastNews?pageNumber=4\n",
      "2025-04-17 04:17:02,383 - INFO - Found 50 articles with selector div.post-wrap\n",
      "2025-04-17 04:17:02,425 - INFO - Page 4: Extracted 50 articles\n",
      "2025-04-17 04:17:02,425 - INFO - Scraping page 5: https://english.wafa.ps/Pages/LastNews?pageNumber=5\n",
      "2025-04-17 04:17:03,588 - INFO - Found 50 articles with selector div.post-wrap\n",
      "2025-04-17 04:17:03,632 - INFO - Page 5: Extracted 50 articles\n",
      "2025-04-17 04:17:03,705 - INFO - Saved 143 articles to wafa_latest_news.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from requests.exceptions import RequestException\n",
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"wafa_scraper.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Constants\n",
    "CSV_FILE_NAME = \"wafa_latest_news.csv\"\n",
    "BASE_URL_TEMPLATE = \"https://english.wafa.ps/Pages/LastNews?pageNumber={}\"  # 1-5\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "}\n",
    "REQUEST_TIMEOUT = 15\n",
    "\n",
    "GAZA_TERMS = [\n",
    "    \"gaza\", \"north gaza\", \"south gaza\", \"central gaza\", \"gaza city\", \"deir al-balah\",\n",
    "    \"khan younis\", \"rafah\", \"gaza strip\", \"palestinian enclave\", \"beach camp\", \"al-shati\",\n",
    "    \"jabalia\", \"beit hanoun\", \"beit lahia\", \"al-zahra\", \"al-maghazi\", \"al-bureij\",\n",
    "    \"nuseirat\", \"al-quds\", \"tuffah\", \"shuja'iyya\", \"remal\", \"daraj\", \"al-sabra\",\n",
    "    \"al-tuffah\", \"al-nasr\", \"al-rijal\", \"al-katiba\", \"al-awda\", \"al-shifa\"\n",
    "]\n",
    "WEST_BANK_TERMS = [\n",
    "    \"west bank\", \"jenin\", \"tubas\", \"tulkarm\", \"nablus\", \"naplouse\", \"nablus\",\n",
    "    \"qalqilya\", \"salfit\", \"ramallah\", \"al-bireh\", \"jericho\", \"ariha\",\n",
    "    \"bethlehem\", \"beit lahm\", \"hebron\", \"al-khalil\", \"jerusalem\", \"al-quds\",\n",
    "    \"occupied territories\", \"silwan\", \"sheikh jarrah\", \"abu dis\", \"al-ram\",\n",
    "    \"beitar illit\", \"ma'ale adumim\", \"ariel\", \"al-khalayleh\", \"al-azzariya\",\n",
    "    \"al-eizariya\", \"beita\", \"huwara\", \"yatta\", \"al-samu\", \"al-arrub\", \"al-fawwar\",\n",
    "    \"al-bireh\", \"biddu\", \"beitin\", \"burqa\", \"al-jalazun\", \"al-mazra'a\", \"President Abbas\",\n",
    "    \"settler\", \"settlers\", \"colonist\", \"colonists\",  \"colonial\", \"colonialist\", \"colonialists\"\n",
    "]\n",
    "\n",
    "ATTACK_KEYWORDS = [\n",
    "    ([\"airstrike\", \"airstrikes\", \"air strike\", \"air strikes\", \"air raid\", \"air raids\", \n",
    "      \"bombardment\", \"shelling\", \"artillery\", \"missile\", \"missiles\", \"f16\", \"f-16\", \n",
    "      \"fighter jet\", \"fighter jets\", \"drone strike\", \"drone strikes\", \"drone\", \"drones\", \"helicopter\", \"jet\", \"air\"], \"airstrike\"),\n",
    "    ([\"demolish\", \"demolition\", \"demolitions\", \"bulldozer\", \"bulldozers\", \"bulldoze\", \n",
    "      \"home demolition\", \"house demolition\", \"structure demolition\", \"raze\", \"razing\", \n",
    "      \"destroyed home\", \"destroyed houses\"], \"demolition\"),\n",
    "    ([\"shoot\", \"shooting\", \"shot\", \"gunfire\", \"gun shot\", \"gun shots\", \"gunshot\", \n",
    "      \"gunshots\", \"live fire\", \"fired at\", \"fired upon\", \"open fire\", \"opened fire\", \n",
    "      \"sniper\", \"snipers\"], \"shooting\"),\n",
    "    ([\"bomb\", \"bombs\", \"bombing\", \"bombings\", \"explosion\", \"explosions\", \"explosive\", \n",
    "      \"exploded\", \"detonate\", \"detonation\", \"shell\", \"shells\", \"mortar\", \"mortars\", \n",
    "      \"grenade\", \"grenades\"], \"bomb\"),\n",
    "    ([\"raid\", \"raids\", \"military raid\", \"night raid\", \"search raid\", \"invasion\", \n",
    "      \"storm\", \"storming\", \"break in\", \"forced entry\", \"incursion\", \"incursions\"], \"raid\"),\n",
    "    ([\"settler\", \"settlers\", \"colonist\", \"colonists\", \"settler attack\", \"settler violence\", \n",
    "      \"settler aggression\", \"settler rampage\", \"settler riot\", \"settler pogrom\",\n",
    "      \"colonial\", \"colonialist\", \"colonialists\"], \"settler\"),\n",
    "    ([\"arrest\", \"arrests\", \"detain\", \"detention\", \"detained\", \"kidnap\", \"abduct\", \n",
    "      \"abduction\", \"capture\", \"imprison\", \"imprisonment\", \"take into custody\"], \"arrest\"),\n",
    "    ([\"blockade\", \"siege\", \"closure\", \"checkpoint\", \"checkpoints\", \"barrier\", \n",
    "      \"curfew\", \"movement restriction\", \"travel ban\", \"access denied\"], \"restriction\"),\n",
    "    ([\"genocide\", \"ethic cleansing\", \"force displacement\", \"starvation\"], \"crimes against humanity\"),\n",
    "]\n",
    "\n",
    "EVENT_KEYWORDS = {\n",
    "    \"Killings\": [\n",
    "        \"kill\", \"killed\", \"killing\", \"death\", \"deaths\", \"die\", \"died\", \"dead\", \n",
    "        \"fatality\", \"fatalities\", \"slain\", \"murder\", \"murdered\", \"massacre\", \n",
    "        \"execute\", \"executed\", \"execution\", \"martyr\", \"martyrs\", \"martyrdom\",\n",
    "        \"assassinate\", \"assassination\", \"slaughter\", \"mass killing\", \"genocide\",\n",
    "        \"ethnic cleansing\", \"lost their lives\", \"were killed\", \"found dead\", \"succumb\", \"succumbs\"\n",
    "    ],\n",
    "    \n",
    "    \"Injury\": [\n",
    "        \"injure\", \"injured\", \"injury\", \"injuries\", \"wound\", \"wounded\", \"wounds\",\n",
    "        \"hurt\", \"maim\", \"maimed\", \"critical condition\", \"seriously hurt\", \"hospitalized\",\n",
    "        \"amputee\", \"amputation\", \"bleeding\", \"trauma\", \"shrapnel\", \"fracture\",\n",
    "        \"burn\", \"burns\", \"medical attention\", \"treated for wounds\", \"sustained injuries\"\n",
    "    ],\n",
    "    \n",
    "    \"Displacement\": [\n",
    "        \"displace\", \"displaced\", \"evacuate\", \"evacuated\", \"eviction\", \"expel\",\n",
    "        \"expelled\", \"forced out\", \"flee\", \"fled\", \"flight\", \"refugee\", \"refugees\",\n",
    "        \"idp\", \"internally displaced\", \"homeless\", \"lost their home\", \"house destroyed\",\n",
    "        \"shelter\", \"makeshift shelter\", \"tent\", \"tents\", \"camp\", \"camps\", \"exodus\", \"displacement\"\n",
    "    ],\n",
    "    \n",
    "    \"Demonstration\": [\n",
    "        \"protest\", \"protests\", \"protestor\", \"protestors\", \"demonstration\", \n",
    "        \"demonstrations\", \"march\", \"marches\", \"rally\", \"rallies\", \"sit-in\",\n",
    "        \"strike\", \"general strike\", \"day of rage\", \"clash\", \"clashes\", \"confrontation\",\n",
    "        \"confrontations\", \"resistance\", \"solidarity\", \"mobilization\", \"gathering\",\n",
    "        \"gatherings\", \"vigil\", \"vigils\", \"civil disobedience\", \"popular resistance\"\n",
    "    ],\n",
    "    \n",
    "    \"Children\": [\n",
    "        \"child\", \"children\", \"minor\", \"minors\", \"boy\", \"boys\", \"girl\", \"girls\",\n",
    "        \"baby\", \"babies\", \"infant\", \"infants\", \"toddler\", \"toddlers\", \"teen\", \"teens\",\n",
    "        \"teenager\", \"teenagers\", \"youth\", \"youngster\", \"youngsters\", \"schoolchild\",\n",
    "        \"schoolchildren\", \"kindergarten\", \"pediatric\", \"newborn\", \"newborns\", \"underage\"\n",
    "    ],\n",
    "    \n",
    "    \"Hostages\": [\n",
    "        \"hostage\", \"hostages\", \"captive\", \"captives\", \"prisoner\", \"prisoners\",\n",
    "        \"detainee\", \"detainees\", \"abductee\", \"abductees\", \"kidnap victim\", \n",
    "        \"held captive\", \"being held\", \"in custody\", \"unlawful detention\",\n",
    "        \"illegal detention\", \"political prisoner\", \"administrative detention\"\n",
    "    ],\n",
    "    \n",
    "    \"Medical Infrastructure\": [\n",
    "        \"hospital\", \"hospitals\", \"clinic\", \"clinics\", \"medical center\", \n",
    "        \"health facility\", \"ambulance\", \"ambulances\", \"paramedic\", \"paramedics\",\n",
    "        \"doctor\", \"doctors\", \"nurse\", \"nurses\", \"physician\", \"physicians\",\n",
    "        \"medical staff\", \"health worker\", \"health workers\", \"icu\", \"emergency room\",\n",
    "        \"er\", \"operating room\", \"medical supplies\", \"medicine shortage\",\n",
    "        \"pharmacy\", \"pharmacies\", \"red crescent\", \"medical aid\", \"field hospital\",\n",
    "        \"mobile clinic\", \"vaccination\", \"vaccine\", \"vaccines\", \"medication\",\n",
    "        \"medications\", \"treatment\", \"treatments\", \"surgery\", \"surgeries\",\n",
    "        \"medical equipment\", \"oxygen\", \"ventilator\", \"ventilators\"\n",
    "    ],\n",
    "    \n",
    "    \"Education\": [\n",
    "        \"school\", \"schools\", \"university\", \"universities\", \"college\", \"colleges\",\n",
    "        \"kindergarten\", \"kindergartens\", \"students\", \"teachers\", \"education\",\n",
    "        \"educational\", \"academic\", \"classroom\", \"classrooms\", \"textbook\",\n",
    "        \"textbooks\", \"curriculum\", \"scholar\", \"scholars\", \"professor\",\n",
    "        \"professors\", \"lecturer\", \"lecturers\", \"student union\", \"tuition\",\n",
    "        \"scholarship\", \"scholarships\", \"educational materials\", \"school supplies\"\n",
    "    ],\n",
    "    \n",
    "    \"Infrastructure\": [\n",
    "        \"electricity\", \"power plant\", \"power grid\", \"water supply\", \"sewage\",\n",
    "        \"sanitation\", \"roads\", \"bridge\", \"bridges\", \"tunnel\", \"tunnels\",\n",
    "        \"communication\", \"internet\", \"telecom\", \"telecommunications\", \"network\",\n",
    "        \"networks\", \"construction\", \"rebuilding\", \"reconstruction\", \"repair\",\n",
    "        \"repairs\", \"damage\", \"destroyed infrastructure\", \"public works\",\n",
    "        \"housing\", \"homes\", \"apartment\", \"apartments\", \"building\", \"buildings\"\n",
    "    ],\n",
    "    \n",
    "    \"Food Security\": [\n",
    "        \"hunger\", \"starvation\", \"famine\", \"malnutrition\", \"food shortage\",\n",
    "        \"food aid\", \"humanitarian aid\", \"relief\", \"food supplies\", \"rations\",\n",
    "        \"nutrition\", \"undernourished\", \"food insecurity\", \"food distribution\",\n",
    "        \"food parcels\", \"food packages\", \"humanitarian corridor\", \"aid convoy\",\n",
    "        \"blockade\", \"siege\", \"access restrictions\", \"humanitarian access\"\n",
    "    ],\n",
    "    \n",
    "    \"Legal\": [\n",
    "        \"court\", \"courts\", \"judge\", \"judges\", \"lawyer\", \"lawyers\", \"attorney\",\n",
    "        \"attorneys\", \"trial\", \"trials\", \"verdict\", \"verdicts\", \"ruling\",\n",
    "        \"rulings\", \"appeal\", \"appeals\", \"lawsuit\", \"lawsuits\", \"legal action\",\n",
    "        \"legal proceedings\", \"international law\", \"human rights\", \"war crimes\",\n",
    "        \"crime against humanity\", \"icc\", \"international criminal court\",\n",
    "        \"investigation\", \"investigations\", \"probe\", \"inquiry\", \"inquiries\", \"ICJ\"\n",
    "    ],\n",
    "\n",
    "    \"Religion\": [\n",
    "        \"Mosque\", \"Church\", \"Tomb\", \"Christians\", \"Muslims\", \"Muslim\", \"Christian\", \"Joseph's\"\n",
    "    ],\n",
    "\n",
    "    \"Theft\": [\"steal\"\n",
    "    ],\n",
    "\n",
    "    \"United Nations\": [\"UN\", \"United Nations\", \"UNRWA\", \"Security Council\"\n",
    "    ],\n",
    "\n",
    "    \"Hamas\": [\"Hamas\"],\n",
    "\n",
    "    \"Palestine Authority\": [\"President Abbas\", \"Palestine Authority\", \"Fatah\", \"Palestinian National Authority\"], \n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "ARTICLE_SELECTORS = [\n",
    "    (\"div\", \"post-wrap\"),\n",
    "    (\"article\", None),\n",
    "    (\"div\", \"news-item\"),\n",
    "    (\"div\", \"article\"),\n",
    "    (\"li\", \"news-list-item\")\n",
    "]\n",
    "\n",
    "def get_webpage_content(url: str) -> Optional[bytes]:\n",
    "    try:\n",
    "        response = requests.get(url, headers=REQUEST_HEADERS, timeout=REQUEST_TIMEOUT)\n",
    "        response.raise_for_status()\n",
    "        if not response.content or len(response.content) < 500:\n",
    "            logging.warning(f\"Page content seems too small: {len(response.content)} bytes\")\n",
    "            return None\n",
    "        return response.content\n",
    "    except RequestException as e:\n",
    "        logging.error(f\"Failed to fetch webpage {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_articles(soup: BeautifulSoup) -> List:\n",
    "    for tag, class_name in ARTICLE_SELECTORS:\n",
    "        try:\n",
    "            if class_name:\n",
    "                articles = soup.find_all(tag, class_=class_name)\n",
    "            else:\n",
    "                articles = soup.find_all(tag)\n",
    "            if articles:\n",
    "                logging.info(f\"Found {len(articles)} articles with selector {tag}.{class_name if class_name else '*'}\")\n",
    "                return articles\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error with selector {tag}.{class_name}: {e}\")\n",
    "    logging.warning(\"No articles found with any selector!\")\n",
    "    return []\n",
    "\n",
    "def contains_any(text: str, keywords: List[str]) -> bool:\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    text = text.lower()\n",
    "    return any(\n",
    "        re.search(r'\\b' + re.escape(word.lower()) + r'\\b', text) \n",
    "        for word in keywords\n",
    "    )\n",
    "\n",
    "def extract_events(headline: str) -> str:\n",
    "    labels = []\n",
    "    for label, keywords in EVENT_KEYWORDS.items():\n",
    "        if contains_any(headline, keywords):\n",
    "            labels.append(label)\n",
    "    labels = list(dict.fromkeys(labels))\n",
    "    return ', '.join(labels) if labels else \"Not Coded\"\n",
    "\n",
    "def extract_article_data(article) -> Dict:\n",
    "    data = {\n",
    "        \"Date\": \"\",\n",
    "        \"Time\": \"\",\n",
    "        \"Headline\": \"\",\n",
    "        \"URL\": \"\",\n",
    "        \"Location\": \"\",\n",
    "        \"Attack\": \"Not Coded\",\n",
    "        \"Events\": \"Not Coded\"\n",
    "    }\n",
    "    relative_url = \"\"\n",
    "    headline_tag = article.find([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"a\"])\n",
    "    if headline_tag:\n",
    "        if headline_tag.name == \"a\":\n",
    "            data[\"Headline\"] = headline_tag.get_text(strip=True)\n",
    "            relative_url = headline_tag[\"href\"]\n",
    "        else:\n",
    "            data[\"Headline\"] = headline_tag.get_text(strip=True)\n",
    "            a_tag = headline_tag.find(\"a\")\n",
    "            if a_tag and a_tag.has_attr(\"href\"):\n",
    "                relative_url = a_tag[\"href\"]\n",
    "        if relative_url and not relative_url.startswith(\"http\"):\n",
    "            data[\"URL\"] = f\"https://english.wafa.ps{relative_url}\"\n",
    "        elif relative_url:\n",
    "            data[\"URL\"] = relative_url\n",
    "    date_time_tag = article.find([\"span\", \"div\", \"time\"], class_=re.compile(r\"date|time|meta\", re.I))\n",
    "    if date_time_tag:\n",
    "        date_time_text = date_time_tag.text.strip()\n",
    "        try:\n",
    "            for fmt in (\"%d/%B/%Y %I:%M %p\", \"%Y-%m-%d %H:%M:%S\", \"%B %d, %Y\", \"%d-%m-%Y\"):\n",
    "                try:\n",
    "                    date_time_obj = datetime.strptime(date_time_text, fmt)\n",
    "                    data[\"Date\"] = date_time_obj.strftime(\"%Y-%m-%d\")\n",
    "                    data[\"Time\"] = date_time_obj.strftime(\"%H:%M:%S\")\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not parse date: {date_time_text} - {e}\")\n",
    "    headline_lower = data[\"Headline\"].lower()\n",
    "    # Location: ensure \"Gaza\" and \"West Bank\" are capitalized exactly\n",
    "    for term in GAZA_TERMS:\n",
    "        if term in headline_lower:\n",
    "            data[\"Location\"] = \"Gaza\"\n",
    "            break\n",
    "    if not data[\"Location\"]:\n",
    "        for term in WEST_BANK_TERMS:\n",
    "            if term in headline_lower:\n",
    "                data[\"Location\"] = \"West Bank\"\n",
    "                break\n",
    "    # Attack: if not found, stays \"Not Coded\"\n",
    "    for keywords, attack_type in ATTACK_KEYWORDS:\n",
    "        if any(re.search(r'\\b' + re.escape(kw) + r'\\b', headline_lower) for kw in keywords):\n",
    "            data[\"Attack\"] = attack_type\n",
    "            break\n",
    "    data[\"Events\"] = extract_events(data[\"Headline\"])\n",
    "    return data\n",
    "\n",
    "def scrape_page(page_num: int) -> List[Dict]:\n",
    "    url = BASE_URL_TEMPLATE.format(page_num)\n",
    "    logging.info(f\"Scraping page {page_num}: {url}\")\n",
    "    content = get_webpage_content(url)\n",
    "    if not content:\n",
    "        return []\n",
    "    soup = BeautifulSoup(content, \"html.parser\")\n",
    "    articles = find_articles(soup)\n",
    "    scraped_data = []\n",
    "    for article in articles:\n",
    "        try:\n",
    "            article_data = extract_article_data(article)\n",
    "            if article_data[\"Headline\"]:\n",
    "                scraped_data.append(article_data)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing article: {e}\")\n",
    "            continue\n",
    "    logging.info(f\"Page {page_num}: Extracted {len(scraped_data)} articles\")\n",
    "    return scraped_data\n",
    "\n",
    "def save_to_csv(data: List[Dict], filename: str) -> bool:\n",
    "    if not data:\n",
    "        logging.warning(\"No data to save!\")\n",
    "        return False\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [\"Date\", \"Time\", \"Headline\", \"URL\", \"Location\", \"Attack\", \"Events\"]\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "    df = df[columns]\n",
    "    # Fill empty/blank Attack cells with \"Not Coded\"\n",
    "    df['Attack'] = df['Attack'].replace('', 'Not Coded')\n",
    "    # Ensure Location is exactly \"Gaza\", \"West Bank\", or blank\n",
    "    df['Location'] = df['Location'].apply(lambda x: \"Gaza\" if x.lower() == \"gaza\" else (\"West Bank\" if x.lower() == \"west bank\" else \"\"))\n",
    "    # Sort by Date descending (newest first)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.sort_values(by='Date', ascending=False)\n",
    "    # Handle existing file\n",
    "    if os.path.exists(filename):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(filename)\n",
    "            existing_df['Date'] = pd.to_datetime(existing_df['Date'], errors='coerce')\n",
    "            combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "            combined_df = combined_df.drop_duplicates(\n",
    "                subset=[\"Headline\", \"Date\"], \n",
    "                keep=\"last\"\n",
    "            )\n",
    "            combined_df[\"Events\"] = combined_df.apply(\n",
    "                lambda row: extract_events(row[\"Headline\"]),\n",
    "                axis=1\n",
    "            )\n",
    "            # Fill empty/blank Attack cells with \"Not Coded\"\n",
    "            combined_df['Attack'] = combined_df['Attack'].replace('', 'Not Coded')\n",
    "            # Ensure Location is exactly \"Gaza\", \"West Bank\", or blank\n",
    "            combined_df['Location'] = combined_df['Location'].apply(lambda x: \"Gaza\" if str(x).lower() == \"gaza\" else (\"West Bank\" if str(x).lower() == \"west bank\" else \"\"))\n",
    "            # Sort newest first\n",
    "            combined_df = combined_df.sort_values(by='Date', ascending=False)\n",
    "            df = combined_df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error merging with existing file: {e}\")\n",
    "            return False\n",
    "    try:\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        logging.info(f\"Saved {len(df)} articles to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "def scrape_and_export_csv():\n",
    "    all_data = []\n",
    "    for page_num in range(1, 6):\n",
    "        try:\n",
    "            page_data = scrape_page(page_num)\n",
    "            all_data.extend(page_data)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scraping page {page_num}: {e}\")\n",
    "            continue\n",
    "    if not save_to_csv(all_data, CSV_FILE_NAME):\n",
    "        logging.error(\"Failed to save data to CSV\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_and_export_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571af140-1b8c-4a7a-ba82-5e921f27b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "         Date      Time                                           Headline  \\\n",
      "0  2025-04-17  08:40:00   UN: Israel continues to obstruct distributio ...   \n",
      "1  2025-04-17  10:50:00  Thousands of Israeli colonists break into Jeru...   \n",
      "2  2025-04-17  08:42:00   China and Malaysia reject displacement, call ...   \n",
      "3  2025-04-17  10:21:00       Palestinian detainee dies in Israeli custody   \n",
      "4  2025-04-17  10:50:00   Thousands of Israeli colonists break into Je ...   \n",
      "\n",
      "                                            URL   Location     Attack  \\\n",
      "0  https://english.wafa.ps/Pages/Details/156537        NaN  Not Coded   \n",
      "1  https://english.wafa.ps/Pages/Details/156540  West Bank    settler   \n",
      "2  https://english.wafa.ps/Pages/Details/156538        NaN  Not Coded   \n",
      "3  https://english.wafa.ps/Pages/Details/156539        NaN  Not Coded   \n",
      "4  https://english.wafa.ps/Pages/Details/156540  West Bank    settler   \n",
      "\n",
      "           Events  Summary  \n",
      "0  United Nations      NaN  \n",
      "1       Not Coded      NaN  \n",
      "2       Not Coded      NaN  \n",
      "3        Hostages      NaN  \n",
      "4       Not Coded      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('wafa_latest_news.csv')\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"First few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46741462-b053-475a-8008-399a1b5fc3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
